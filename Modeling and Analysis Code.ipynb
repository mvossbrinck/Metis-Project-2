{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Open Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data Sets/Final_Data_Set.pickle','rb') as read_file:\n",
    "    recipe_data = pickle.load(read_file)\n",
    "\n",
    "recipe_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns and handle nulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = recipe_data.drop(columns = ['name', 'recipe_time', 'number_of_servings', \n",
    "                                         'image_link', 'recipe_link', 'recipe_start_date', \n",
    "                                         'name_other', 'recipe_categories', 'recipe_keywords'\n",
    "                                        ])\n",
    "\n",
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Four variables have nulls - number of ratings, number of steps, rating value, and days ago. \n",
    "I'm choosing to fill in the nulls for number of ratings with zero since it is valid for there\n",
    "to be no ratings and zero ratings accurately numerically reflects that.\n",
    "I'm filling in the other nulls with mean because number of steps cannot be zero, I think \n",
    "assuming rating values would be zero if there are no ratings is more likely to create a \n",
    "false relationship in the data than assuming the rating values are the mean. With days ago,\n",
    "I think there is a chance it's more likely to be recent if it has no rating, but I cannot say \n",
    "that for sure and don't want to create a false relationship between no ratings and days\n",
    "ago. It's a flawed approach to handling nulls, but I think it's the most appropriate.\n",
    "'''\n",
    "model_data['number_of_ratings'] = model_data['number_of_ratings'].fillna(0)  \n",
    "model_data.fillna(model_data.mean(), inplace = True)\n",
    "model_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Tables and Pair Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12)) \n",
    "sns.heatmap(model_data.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_limited = model_data.loc[:,['number_of_steps', 'number_of_ratings', 'rating_value', 'number_of_ingredients', 'recipe_time_in_min', 'days_ago']]\n",
    "sns.pairplot(model_data_limited);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "I did try a square root and log transformation of number of ratings. For log, I ran into \n",
    "issues with zeros. One article I found about transformations mentioned adding a constant \n",
    "to all the values to remove the zero issue. I tried it but wasn't sure if\n",
    "it was a valid approach. I discussed the log transformation with Vinny and he pointed \n",
    "out that there would be interpretation issues. I want the model to be something that can \n",
    "be understood so I mainly focused on the non transformed number of ratings, but have added \n",
    "the results from the square root and log transformations at the end\n",
    "'''\n",
    "\n",
    "# Number of Ratings Transformations \n",
    "model_data['number_of_ratings_sqrt'] = np.sqrt(model_data['number_of_ratings'])\n",
    "model_data['number_of_ratings_plus1'] = (model_data['number_of_ratings']+1)\n",
    "model_data['number_of_ratings_log'] = np.log(model_data['number_of_ratings_plus1'])\n",
    "\n",
    "# Transforming feature variables based on patterns in pair plots\n",
    "model_data['days_ago_sq'] = model_data['days_ago']**2\n",
    "model_data['recipe_time_in_min_sqrt'] = np.sqrt(model_data['recipe_time_in_min'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data[['number_of_steps', 'rating_value', 'author', 'number_of_ingredients', \n",
    "                   'main_course', 'dinner', 'side_dish', 'easy', 'dessert', 'quick', \n",
    "                   'weekday', 'appetizer', 'lunch', 'vegetarian', 'fall', 'winter', 'summer',\n",
    "                   'recipe_time_in_min', 'days_ago', 'days_ago_sq', 'recipe_time_in_min_sqrt']]\n",
    "\n",
    "y = model_data['number_of_ratings']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with only non transformed numeric variables\n",
    "\n",
    "selected_columns = ['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                     'recipe_time_in_min', 'days_ago']\n",
    "\n",
    "m = LinearRegression()\n",
    "m.fit(X_train.loc[:,selected_columns],y_train)\n",
    "m.score(X_train.loc[:,selected_columns],y_train)\n",
    "\n",
    "# Results in a 0.093 R squared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(X_val.loc[:,selected_columns],y_val)\n",
    "# Validation R squared is only 0.104 so moving on to different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with all numeric variables\n",
    "selected_columns = ['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                     'recipe_time_in_min', 'days_ago', 'days_ago_sq', 'recipe_time_in_min_sqrt']\n",
    "\n",
    "m = LinearRegression()\n",
    "m.fit(X_train.loc[:,selected_columns],y_train)\n",
    "m.score(X_train.loc[:,selected_columns],y_train)\n",
    "\n",
    "# Results in a 0.097 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(X_val.loc[:,selected_columns],y_val)\n",
    "# Validation R squared is only 0.102 so moving on to different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial model degree 2 with all non transformed numeric variables \n",
    "selected_columns = ['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                     'recipe_time_in_min', 'days_ago']\n",
    "\n",
    "m = LinearRegression()\n",
    "p = PolynomialFeatures(degree=2)\n",
    "m.fit(p.fit_transform(X_train.loc[:,selected_columns]),y_train)\n",
    "m.score(p.transform(X_train.loc[:,selected_columns]),y_train)\n",
    "\n",
    "# Results in a 0.110 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(p.transform(X_val.loc[:,selected_columns]),y_val)\n",
    "# Validation R squared is 0.107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial model degree 3 with all non transformed numeric variables \n",
    "selected_columns = ['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                     'recipe_time_in_min', 'days_ago']\n",
    "\n",
    "m = LinearRegression()\n",
    "p = PolynomialFeatures(degree=3)\n",
    "m.fit(p.fit_transform(X_train.loc[:,selected_columns]),y_train)\n",
    "m.score(p.transform(X_train.loc[:,selected_columns]),y_train)\n",
    "\n",
    "# Results in a 0.144 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(p.transform(X_val.loc[:,selected_columns]),y_val)\n",
    "# Validation R squared of 0.102, suggesting that it is somewhat overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyword Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When looking at the possible categories and keywords for a recipe, I handled them similarly and thought\n",
    "# of them all as 'keyword tags'. In the data set cleaning code, I created binary variables for any of them\n",
    "# where at least 10% of the recipes were tagged with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with all numeric variables and keyword tags\n",
    "\n",
    "selected_columns = ['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                     'recipe_time_in_min', 'days_ago', 'days_ago_sq', 'recipe_time_in_min_sqrt',\n",
    "                     'main_course', 'dinner', 'side_dish', 'easy', 'dessert', 'quick', 'weekday', \n",
    "                     'appetizer', 'lunch', 'vegetarian', 'fall', 'winter', 'summer']\n",
    "\n",
    "m = LinearRegression()\n",
    "m.fit(X_train.loc[:,selected_columns],y_train)\n",
    "m.score(X_train.loc[:,selected_columns],y_train)\n",
    "\n",
    "# Results in a 0.131 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(X_val.loc[:,selected_columns],y_val)\n",
    "#Validation R squared is 0.119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used LassoCV to see if there were too many variables and dropping some would help with fit\n",
    "\n",
    "m = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_scaled = s.fit_transform(X_train.loc[:,selected_columns])\n",
    "m.fit(X_train_scaled,y_train)\n",
    "m.score(X_train_scaled,y_train)\n",
    "\n",
    "# Results in a 0.131 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = s.transform(X_val.loc[:,selected_columns])\n",
    "m.score(X_val_scaled,y_val)\n",
    "# Validation R squared is 0.119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I then tried LassoCV with Polynomial Features of degree 2\n",
    "\n",
    "selected_columns = ['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                     'recipe_time_in_min', 'days_ago',\n",
    "                     'main_course', 'dinner', 'side_dish', 'easy', 'dessert', 'quick', 'weekday', \n",
    "                     'appetizer', 'lunch', 'vegetarian', 'fall', 'winter', 'summer']\n",
    "\n",
    "\n",
    "m = LassoCV()\n",
    "p = PolynomialFeatures(degree=2)\n",
    "X_train_poly = p.fit_transform(X_train.loc[:,selected_columns])\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_poly_scaled = s.fit_transform(X_train_poly)\n",
    "m.fit(X_train_poly_scaled,y_train)\n",
    "m.score(X_train_poly_scaled,y_train)\n",
    "\n",
    "# Results in a 0.154 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_poly_scaled = s.transform(p.transform(X_val.loc[:,selected_columns]))\n",
    "m.score(X_val_poly_scaled,y_val)\n",
    "# Validation R squared is 0.103 which suggests overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking a couple of the keyword tags to see how much overlap there is\n",
    "X_train.groupby([\"main_course\", \"dinner\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby([\"easy\", \"quick\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the limited improvement in R squared from using keyword tags, I decided to remove them when\n",
    "# adding author. The overlap between some of the keyword tags is also concerning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding top 10 authors by total number of ratings\n",
    "all_train = pd.concat([X_train, y_train], axis=1)\n",
    "author_data = all_train.groupby('author').sum('number_of_ratings')\n",
    "author_data.sort_values(by='number_of_ratings', ascending=False, inplace = True)\n",
    "author_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Author Category to data\n",
    "X_train['author_category'] = np.where(X_train['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_train['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_train['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_train['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_train['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_train['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_train['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Author Category for training data \n",
    "\n",
    "cat_X = X_train.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X)\n",
    "ohe_X = ohe.transform(cat_X)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df = pd.DataFrame(ohe_X, columns = columns, index=cat_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining categorical author variable with rest of data set and limiting it to numeric variables \n",
    "# and author category\n",
    "\n",
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df = combined_df[['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                          'recipe_time_in_min', 'days_ago', 'days_ago_sq', 'recipe_time_in_min_sqrt',                     \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lr = LinearRegression()\n",
    "combined_lr.fit(combined_df, y_train)\n",
    "combined_lr.score(combined_df, y_train)\n",
    "# Results in 0.159 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Author Category for validation data \n",
    "X_val['author_category'] = np.where(X_val['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_val['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_val['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_val['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_val['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_val['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_val['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "cat_X_val = X_val.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X_val)\n",
    "ohe_X_val = ohe.transform(cat_X_val)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df_val = pd.DataFrame(ohe_X_val, columns = columns, index=cat_X_val.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining categorical author variable with rest of data set and limiting it to numeric variables \n",
    "# and author category\n",
    "\n",
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val = combined_df_val[['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                          'recipe_time_in_min', 'days_ago', 'days_ago_sq', 'recipe_time_in_min_sqrt',                     \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lr.score(combined_df_val, y_val)\n",
    "# Validation R squared is 0.143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LassoCV to see if any variables drop out or have low impact\n",
    "m = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_scaled = s.fit_transform(combined_df)\n",
    "m.fit(X_train_scaled,y_train)\n",
    "m.score(X_train_scaled,y_train)\n",
    "# Results in a 0.159 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(s.transform(combined_df_val),y_val)\n",
    "# Validation R squared is 0.143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(combined_df.columns,m.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model run without number of steps and number of ingredients due to zeroing out or low effect coefficients\n",
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df = combined_df[[ 'rating_value',\n",
    "                          'recipe_time_in_min', 'days_ago', 'days_ago_sq', 'recipe_time_in_min_sqrt',                     \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val = combined_df_val[[ 'rating_value',\n",
    "                          'recipe_time_in_min', 'days_ago', 'days_ago_sq', 'recipe_time_in_min_sqrt',                     \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_scaled = s.fit_transform(combined_df)\n",
    "m.fit(X_train_scaled,y_train)\n",
    "m.score(X_train_scaled,y_train)\n",
    "# Results in a 0.158 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(s.transform(combined_df_val),y_val)\n",
    "# Validation R squared is 0.142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(combined_df.columns,m.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model run without transformed numeric variables to see if it makes a difference in R squared\n",
    "# Not having those variables would help simplify interpretation\n",
    "\n",
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df = combined_df[[ 'rating_value', 'recipe_time_in_min',\n",
    "                           'days_ago',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val = combined_df_val[[ 'rating_value', 'recipe_time_in_min',\n",
    "                           'days_ago',                 \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_scaled = s.fit_transform(combined_df)\n",
    "m.fit(X_train_scaled,y_train)\n",
    "m.score(X_train_scaled,y_train)\n",
    "# Results in a 0.153 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(s.transform(combined_df_val),y_val)\n",
    "# Validation R squared is 0.140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(combined_df.columns,m.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe time in minutes has a low impact coefficient. I came across an error in data set sorting\n",
    "# after the presentation that could explain why this is now less significant in the mode'.\n",
    "# I will run the model without recipe_time_in_min to see the effect\n",
    "# I do know that the David Tanis variable is zeroed out, but prefer to keep it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df = combined_df[[ 'rating_value', 'days_ago',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val = combined_df_val[[ 'rating_value', 'days_ago',                 \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_scaled = s.fit_transform(combined_df)\n",
    "m2.fit(X_train_scaled,y_train)\n",
    "m2.score(X_train_scaled,y_train)\n",
    "# Results in a 0.153 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.score(s.transform(combined_df_val),y_val)\n",
    "# Validation R squared is 0.139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will try model with and without recipe_time_in_min on train_val data and then test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Author Category for training validation full data \n",
    "\n",
    "X_train_val['author_category'] = np.where(X_train_val['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_train_val['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_train_val['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_train_val['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_train_val['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_train_val['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_train_val['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "cat_X_train_val = X_train_val.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X_train_val)\n",
    "ohe_X_train_val = ohe.transform(cat_X_train_val)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df_train_val = pd.DataFrame(ohe_X_train_val, columns = columns, index=cat_X_train_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Author Category for test data \n",
    "\n",
    "X_test['author_category'] = np.where(X_test['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_test['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_test['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_test['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_test['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_test['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_test['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "cat_X_test = X_test.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X_test)\n",
    "ohe_X_test = ohe.transform(cat_X_test)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df_test = pd.DataFrame(ohe_X_test, columns = columns, index=cat_X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_train_val = pd.concat([X_train_val, ohe_X_df_train_val], axis=1)\n",
    "combined_df_train_val = combined_df_train_val[[ 'rating_value', 'days_ago',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_test = pd.concat([X_test, ohe_X_df_test], axis=1)\n",
    "combined_df_test = combined_df_test[[ 'rating_value', 'days_ago',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_val_scaled = s.fit_transform(combined_df_train_val)\n",
    "m.fit(X_train_val_scaled,y_train_val)\n",
    "m.score(X_train_val_scaled,y_train_val)\n",
    "# Results in a 0.150 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(s.transform(combined_df_test),y_test)\n",
    "# Test R squared is 0.168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_train_val = pd.concat([X_train_val, ohe_X_df_train_val], axis=1)\n",
    "combined_df_train_val = combined_df_train_val[[ 'rating_value', 'days_ago', 'recipe_time_in_min',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_test = pd.concat([X_test, ohe_X_df_test], axis=1)\n",
    "combined_df_test = combined_df_test[[ 'rating_value', 'days_ago', 'recipe_time_in_min',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_val_scaled = s.fit_transform(combined_df_train_val)\n",
    "m2.fit(X_train_val_scaled,y_train_val)\n",
    "m2.score(X_train_val_scaled,y_train_val)\n",
    "# Results in a 0.151 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.score(s.transform(combined_df_test),y_test)\n",
    "# Test R squared is 0.169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models perform similarly so recipe_time_in_min will be taken out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Models with Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df = combined_df[['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                          'recipe_time_in_min', 'days_ago',                   \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val = combined_df_val[['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                          'recipe_time_in_min', 'days_ago',                    \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LassoCV()\n",
    "p = PolynomialFeatures(degree=2)\n",
    "X_train_poly = p.fit_transform(combined_df)\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_poly_scaled = s.fit_transform(X_train_poly)\n",
    "m.fit(X_train_poly_scaled,y_train)\n",
    "m.score(X_train_poly_scaled,y_train)\n",
    "# Results in a 0.167 R squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_poly_scaled = s.transform(p.transform(combined_df_val))\n",
    "m.score(X_val_poly_scaled,y_val)\n",
    "# Validation R squared is 0.143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial LASSO does not show substantial improvement over simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Keyword Tags Back in just to double check that it does not significantly improve R squared\n",
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df = combined_df[['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                          'recipe_time_in_min', 'days_ago',\n",
    "                           'main_course', 'dinner', 'side_dish', 'easy', 'dessert', 'quick', 'weekday', \n",
    "                           'appetizer', 'lunch', 'vegetarian', 'fall', 'winter', 'summer',\n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val = combined_df_val[['number_of_steps', 'rating_value', 'number_of_ingredients', \n",
    "                          'recipe_time_in_min', 'days_ago',  \n",
    "                          'main_course', 'dinner', 'side_dish', 'easy', 'dessert', 'quick', 'weekday', \n",
    "                           'appetizer', 'lunch', 'vegetarian', 'fall', 'winter', 'summer',\n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LassoCV()\n",
    "p = PolynomialFeatures(degree=2)\n",
    "X_train_poly = p.fit_transform(combined_df)\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_poly_scaled = s.fit_transform(X_train_poly)\n",
    "m.fit(X_train_poly_scaled,y_train)\n",
    "m.score(X_train_poly_scaled,y_train)\n",
    "# R squared is 0.217 but has a does not converge warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_poly_scaled = s.transform(p.transform(combined_df_val))\n",
    "m.score(X_val_poly_scaled,y_val)\n",
    "# Validation R squared is 0.148, suggesting overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model had did not converge warning and was overfit so will not be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models with log and square root transformation of number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Model \n",
    "X = model_data[['number_of_steps', 'rating_value', 'author', 'number_of_ingredients', \n",
    "                   'recipe_time_in_min', 'days_ago']]\n",
    "\n",
    "y = model_data['number_of_ratings_log']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['author_category'] = np.where(X_train['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_train['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_train['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_train['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_train['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_train['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_train['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_X = X_train.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X)\n",
    "ohe_X = ohe.transform(cat_X)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df = pd.DataFrame(ohe_X, columns = columns, index=cat_X.index)\n",
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df.drop(columns = ['author', 'author_category'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['author_category'] = np.where(X_val['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_val['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_val['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_val['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_val['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_val['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_val['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "cat_X_val = X_val.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X_val)\n",
    "ohe_X_val = ohe.transform(cat_X_val)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df_val = pd.DataFrame(ohe_X_val, columns = columns, index=cat_X_val.index)\n",
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val.drop(columns = ['author', 'author_category'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_scaled = s.fit_transform(combined_df)\n",
    "m.fit(X_train_scaled,y_train)\n",
    "m.score(X_train_scaled,y_train)\n",
    "# Results in a R squared of 0.304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(s.transform(combined_df_val),y_val)\n",
    "# Validation R squared is 0.291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model does have a better fit, but it compromises interpretability so I'll stick with the \n",
    "# simpler model. This can be used if a better R squared is the priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square root model\n",
    "X = model_data[['number_of_steps', 'rating_value', 'author', 'number_of_ingredients', \n",
    "                   'recipe_time_in_min', 'days_ago']]\n",
    "\n",
    "y = model_data['number_of_ratings_sqrt']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['author_category'] = np.where(X_train['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_train['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_train['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_train['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_train['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_train['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_train['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_X = X_train.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X)\n",
    "ohe_X = ohe.transform(cat_X)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df = pd.DataFrame(ohe_X, columns = columns, index=cat_X.index)\n",
    "combined_df = pd.concat([X_train, ohe_X_df], axis=1)\n",
    "combined_df.drop(columns = ['author', 'author_category'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['author_category'] = np.where(X_val['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_val['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_val['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_val['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_val['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_val['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_val['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "cat_X_val = X_val.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X_val)\n",
    "ohe_X_val = ohe.transform(cat_X_val)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df_val = pd.DataFrame(ohe_X_val, columns = columns, index=cat_X_val.index)\n",
    "combined_df_val = pd.concat([X_val, ohe_X_df_val], axis=1)\n",
    "combined_df_val.drop(columns = ['author', 'author_category'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LassoCV()\n",
    "s = StandardScaler(with_mean=False)\n",
    "X_train_scaled = s.fit_transform(combined_df)\n",
    "m.fit(X_train_scaled,y_train)\n",
    "m.score(X_train_scaled,y_train)\n",
    "# Results in a 0.287 R squared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(s.transform(combined_df_val),y_val)\n",
    "# Validation R squared is 0.280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The log model has a higher R squared so if a transformation of number of ratings is used, it should \n",
    "# be log, assuming higher R squared is the priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun data source and redo OHE for train_val and test\n",
    "\n",
    "X = model_data[['rating_value', 'author', 'days_ago']]\n",
    "\n",
    "y = model_data['number_of_ratings']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)\n",
    "\n",
    "\n",
    "X_train_val['author_category'] = np.where(X_train_val['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_train_val['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_train_val['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_train_val['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_train_val['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_train_val['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_train_val['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "cat_X_train_val = X_train_val.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X_train_val)\n",
    "ohe_X_train_val = ohe.transform(cat_X_train_val)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df_train_val = pd.DataFrame(ohe_X_train_val, columns = columns, index=cat_X_train_val.index)\n",
    "\n",
    "\n",
    "\n",
    "X_test['author_category'] = np.where(X_test['author'] == 'Melissa Clark', 'Melissa Clark',\n",
    "                                     np.where(X_test['author'] == 'Mark Bittman', 'Mark Bittman',\n",
    "                                     np.where(X_test['author'] == 'Julia Moskin', 'Julia Moskin', \n",
    "                                     np.where(X_test['author'] == 'David Tanis', 'David Tanis',\n",
    "                                     np.where(X_test['author'] == 'Ali Slagle', 'Ali Slagle',\n",
    "                                     np.where(X_test['author'] == 'Alison Roman', 'Alison Roman',\n",
    "                                     np.where(X_test['author'] == 'Sam Sifton', 'Sam Sifton',\n",
    "                                        'AAOther')))))))\n",
    "\n",
    "cat_X_test = X_test.loc[:, ['author_category']]\n",
    "\n",
    "ohe = OneHotEncoder(drop= 'first', sparse=False)\n",
    "\n",
    "ohe.fit(cat_X_test)\n",
    "ohe_X_test = ohe.transform(cat_X_test)\n",
    "columns = ohe.get_feature_names(['author_category'])\n",
    "ohe_X_df_test = pd.DataFrame(ohe_X_test, columns = columns, index=cat_X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset data sources used in model\n",
    "\n",
    "combined_df_train_val = pd.concat([X_train_val, ohe_X_df_train_val], axis=1)\n",
    "combined_df_train_val = combined_df_train_val[[ 'rating_value', 'days_ago',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]\n",
    "\n",
    "combined_df_test = pd.concat([X_test, ohe_X_df_test], axis=1)\n",
    "combined_df_test = combined_df_test[[ 'rating_value', 'days_ago',                  \n",
    "                           'author_category_Ali Slagle', 'author_category_Alison Roman', \n",
    "                           'author_category_David Tanis', 'author_category_Julia Moskin', \n",
    "                           'author_category_Mark Bittman', 'author_category_Melissa Clark',\n",
    "                           'author_category_Sam Sifton']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lr = LinearRegression()\n",
    "combined_lr.fit(combined_df_train_val, y_train_val)\n",
    "combined_lr.score(combined_df_train_val, y_train_val)\n",
    "# R squared = 0.150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lr.score(combined_df_test, y_test)\n",
    "# R squared = 0.168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lr.coef_\n",
    "list(zip(combined_df_train_val.columns,combined_lr.coef_))\n",
    "# Coefficients are different from presentation because of data fix and new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "pred = combined_lr.predict(combined_df_test)\n",
    "mse = mean_squared_error(y_test,pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse\n",
    "# RSME = 689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "mae = mean_absolute_error(y_test,pred)\n",
    "mae\n",
    "# MAE = 390"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Actual vs Predictions and Examining Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,pred)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model predicts better for lower values, but is still not great\n",
    "# It generally underpredicts values, but with lower values it also does overpredict at times\n",
    "# I'll look at residuals to see how much individual observations affect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test = pd.concat([combined_df_test, y_test], axis=1)\n",
    "all_test['res'] = pred - y_test\n",
    "all_test.sort_values(by = 'res', inplace = True)\n",
    "all_test.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There were so many large negative residuals that I ultimately decided not to remove any \n",
    "# individual points. Also, the feature variables weren't particularly different for those \n",
    "# observations, they just had a high number of ratings. I didn't want to remove those \n",
    "# observations because with unknown data I would not have the number of rating information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
